{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "93179240-9c5f-4ba6-a1c7-3a981624f794",
            "metadata": {},
            "source": [
                "# Ingest massive amounts of data to a Vector DB (Amazon OpenSearch)\n",
                "**_Use of Amazon OpenSearch as a vector database for storing embeddings_**\n",
                "\n",
                "This notebook works well with the `Data Science 2.0` kernel on a SageMaker Studio `ml.t3.medium` instance.\n",
                "\n",
                "Here is a list of packages that are used in this notebook.\n",
                "```\n",
                "!pip freeze | grep -E \"sagemaker|boto3\"\n",
                "------------------------------------------\n",
                "boto3==1.28.42\n",
                "sagemaker==2.188.0\n",
                "sagemaker-data-insights @ https://files.pythonhosted.org/packages/70/8b/7c964508afe1dc3535422df8383c022c762c1f1254acb68b29d26b33fe30/sagemaker_data_insights-0.3.3-py3-none-any.whl\n",
                "sagemaker-datawrangler @ https://files.pythonhosted.org/packages/6a/29/6d3da0518cbe72647b164bbdee23f4df3936cf5691fff9b29dc8714115ff/sagemaker_datawrangler-0.4.3-py3-none-any.whl\n",
                "sagemaker-scikit-learn-extension==2.5.0\n",
                "sagemaker-studio-analytics-extension==0.0.19\n",
                "sagemaker-studio-image-build==0.6.0\n",
                "sagemaker-studio-sparkmagic-lib==0.1.4\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "79aae52c-cd7a-4637-a07d-9c0131dc7d0a",
            "metadata": {},
            "source": [
                "## Step 1: Setup\n",
                "Install the required packages."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "87e64f84-b7ac-427d-b5a8-cf98b430be9b",
            "metadata": {
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "!pip install -U sagemaker --quiet\n",
                "!pip install -U sagemaker-studio-image-build==0.6.0 --quiet"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "d88757ba-7ae1-4efb-9c02-ab17ec22e79a",
            "metadata": {
                "tags": []
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "boto3==1.28.42\n",
                        "sagemaker==2.188.0\n",
                        "sagemaker-data-insights @ https://files.pythonhosted.org/packages/70/8b/7c964508afe1dc3535422df8383c022c762c1f1254acb68b29d26b33fe30/sagemaker_data_insights-0.3.3-py3-none-any.whl\n",
                        "sagemaker-datawrangler @ https://files.pythonhosted.org/packages/6a/29/6d3da0518cbe72647b164bbdee23f4df3936cf5691fff9b29dc8714115ff/sagemaker_datawrangler-0.4.3-py3-none-any.whl\n",
                        "sagemaker-scikit-learn-extension==2.5.0\n",
                        "sagemaker-studio-analytics-extension==0.0.19\n",
                        "sagemaker-studio-image-build==0.6.0\n",
                        "sagemaker-studio-sparkmagic-lib==0.1.4\n"
                    ]
                }
            ],
            "source": [
                "!pip freeze | grep -E \"sagemaker|boto3\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c017bc3f-e507-4f0c-b640-ea774c5ea9c8",
            "metadata": {},
            "source": [
                "## Step 2: Download the data \n",
                "\n",
                "In this step we use `wget` to download prepared documents which have been crawled from the OpenSearch documentation and website.\n",
                "\n",
                "Document"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "0eb232ee-6b62-4718-9104-345fe7978703",
            "metadata": {
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "%%sh\n",
                "\n",
                "mkdir -p data\n",
                "cd ./data\n",
                "wget https://raw.githubusercontent.com/deepset-ai/haystack-sagemaker/main/data/opensearch-documentation-2.7.json\n",
                "wget https://raw.githubusercontent.com/deepset-ai/haystack-sagemaker/main/data/opensearch-website.json"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "8ee1fbb8-583a-4c41-a831-715e4250ff3c",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import boto3\n",
                "import sagemaker\n",
                "\n",
                "sagemaker_session = sagemaker.session.Session()\n",
                "aws_region = boto3.Session().region_name\n",
                "bucket = sagemaker_session.default_bucket()\n",
                "\n",
                "aws_region, bucket"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "15667be7-43b5-4954-95e0-885c9173f82c",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Step 3: Load data into OpenSearch\n",
                "\n",
                "We now have a working script that is able to ingest data into an OpenSearch index. But for this to work for massive amounts of data we need to scale up the processing by running this code in a distributed fashion. We will do this using Sagemkaer Processing Job. This involves the following steps:\n",
                "\n",
                "1. Create a custom container in which we will install the `langchain` and `opensearch-py` packges and then upload this container image to Amazon Elastic Container Registry (ECR).\n",
                "2. Use the Sagemaker `ScriptProcessor` class to create a Sagemaker Processing job that will run on multiple nodes.\n",
                "    - The data files available in S3 are automatically distributed across in the Sagemaker Processing Job instances by setting `s3_data_distribution_type='ShardedByS3Key'` as part of the `ProcessingInput` provided to the processing job.\n",
                "    - Each node processes a subset of the files and this brings down the overall time required to ingest the data into Opensearch.\n",
                "    - Each node also uses Python `multiprocessing` to internally also parallelize the file processing. Thus, **there are two levels of parallelization happening, one at the cluster level where individual nodes are distributing the work (files) amongst themselves and another at the node level where the files in a node are also split between multiple processes running on the node**."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b45d2938-994f-432d-8c50-92269f22f4b8",
            "metadata": {},
            "source": [
                "### Create custom container\n",
                "\n",
                "We will now create a container locally and push the container image to ECR. **The container creation process takes about 1 minute**."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "01848619-8b49-48da-8cbf-c9cbbd8d1e40",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "DOCKER_IMAGE = \"haystack-opensearch-indexing-pipeline\"\n",
                "DOCKER_IMAGE_TAG = \"latest\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "97bd70a7-8f61-477c-a8ef-82c0b5cd7821",
            "metadata": {
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "!cd ./container && sm-docker build . --repository {DOCKER_IMAGE}:{DOCKER_IMAGE_TAG}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1089064e-2099-4226-82c1-c7c406203c49",
            "metadata": {},
            "source": [
                "### Create and run the Sagemaker Processing Job\n",
                "\n",
                "Now we will run the Sagemaker Processing Job to ingest the data into OpenSearch."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "28b236a7-b5d2-494e-a3e3-baec94adc3d4",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import sys\n",
                "import time\n",
                "import logging\n",
                "\n",
                "logger = logging.getLogger()\n",
                "logging.basicConfig(format='%(asctime)s,%(module)s,%(processName)s,%(levelname)s,%(message)s', level=logging.INFO, stream=sys.stderr)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "0c8d9a38-ae89-44af-83db-657dd7e851d5",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import json\n",
                "from typing import (\n",
                "    List,\n",
                "    Dict\n",
                ")\n",
                "\n",
                "import boto3\n",
                "\n",
                "\n",
                "def get_cfn_outputs(stack_name: str, region_name: str) -> Dict:\n",
                "    cf_client = boto3.client('cloudformation', region_name=region_name)\n",
                "    response = cf_client.describe_stacks(StackName=stack_name)\n",
                "    outputs = response[\"Stacks\"][0][\"Outputs\"]\n",
                "    return {elem['OutputKey']: elem['OutputValue'] for elem in outputs}\n",
                "\n",
                "\n",
                "def get_opensearch_domain_name(stack_name: str, region_name: str = 'us-east-1'):\n",
                "    outputs = get_cfn_outputs(stack_name, region_name=region_name)\n",
                "    return outputs.get('OpenSearchDomainName', None)\n",
                "\n",
                "def get_opensearch_endpoint(stack_name: str, region_name: str = 'us-east-1'):\n",
                "    outputs = get_cfn_outputs(stack_name, region_name=region_name)\n",
                "    return outputs.get('OpenSearchDomainEndpoint', None)\n",
                "\n",
                "def get_opensearch_client_security_group_id(stack_name: str, region_name: str = 'us-east-1'):\n",
                "    outputs = get_cfn_outputs(stack_name, region_name=region_name)\n",
                "    return outputs.get('OpenSearchClientSecurityGroupId', None)\n",
                "\n",
                "\n",
                "def get_opensearch_subnet_ids(domain_name: str, region_name: str = 'us-east-1') -> List:\n",
                "    assert domain_name\n",
                "    client = boto3.client('opensearch', region_name=aws_region)\n",
                "    response = client.describe_domain_config(\n",
                "        DomainName=domain_name\n",
                "    )\n",
                "    subnet_ids = response['DomainConfig']['VPCOptions']['Options']['SubnetIds']\n",
                "    return subnet_ids\n",
                "\n",
                "\n",
                "def get_secret_name(stack_name: str, region_name: str = 'us-east-1'):\n",
                "    outputs = get_cfn_outputs(stack_name, region_name=region_name)\n",
                "    return outputs.get('MasterUserSecretId', None)\n",
                "\n",
                "\n",
                "def get_secret(secret_name: str, region_name: str = 'us-east-1'):\n",
                "    client = boto3.client('secretsmanager', region_name=region_name)\n",
                "    get_secret_value_response = client.get_secret_value(SecretId=secret_name)\n",
                "    secret = get_secret_value_response['SecretString']\n",
                "\n",
                "    return json.loads(secret)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "29861415-9ad9-44bc-b2f2-ca8bf61dd40c",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "CFN_STACK_NAME = \"RAGHaystackOpenSearchStack\"\n",
                "\n",
                "opensearch_domain_name = get_opensearch_domain_name(CFN_STACK_NAME, region_name=aws_region)\n",
                "opensearch_domain_endpoint = get_opensearch_endpoint(CFN_STACK_NAME, region_name=aws_region)\n",
                "opensearch_client_security_group_id = get_opensearch_client_security_group_id(CFN_STACK_NAME, region_name=aws_region)\n",
                "opensearch_subnet_ids = get_opensearch_subnet_ids(opensearch_domain_name, region_name=aws_region)\n",
                "opensearch_secret_id = get_secret_name(CFN_STACK_NAME, region_name=aws_region)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "1749f0fa-2df2-4289-9033-f429aac6e2f6",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "app_name = \"haystack-rag-app\"\n",
                "account_id = boto3.client(\"sts\").get_caller_identity()[\"Account\"]\n",
                "aws_role = sagemaker.get_execution_role()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "ee287749-00cb-4f08-85d3-122ed362f57e",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from sagemaker.processing import (\n",
                "    ProcessingInput,\n",
                "    ScriptProcessor\n",
                ")\n",
                "from sagemaker.network import NetworkConfig\n",
                "\n",
                "# setup the parameters for the job\n",
                "base_job_name = f\"{app_name}-job\"\n",
                "tags = [{\"Key\": \"data\", \"Value\": app_name}]\n",
                "\n",
                "# use the custom container we just created\n",
                "image_uri = f\"{account_id}.dkr.ecr.{aws_region}.amazonaws.com/{DOCKER_IMAGE}:{DOCKER_IMAGE_TAG}\"\n",
                "\n",
                "# instance type and count determined via trial and error: how much overall processing time\n",
                "# and what compute cost works best for your use-case\n",
                "instance_type = \"ml.c5.2xlarge\"\n",
                "instance_count = 1\n",
                "logger.info(f\"base_job_name={base_job_name}, tags={tags}, image_uri={image_uri}, instance_type={instance_type}, instance_count={instance_count}\")\n",
                "\n",
                "# setup the ScriptProcessor with the above parameters\n",
                "processor = ScriptProcessor(base_job_name=base_job_name,\n",
                "                            image_uri=image_uri,\n",
                "                            role=aws_role,\n",
                "                            instance_type=instance_type,\n",
                "                            instance_count=instance_count,\n",
                "                            command=[\"python3\"],\n",
                "                            network_config=NetworkConfig(\n",
                "                                security_group_ids=[opensearch_client_security_group_id],\n",
                "                                subnets=opensearch_subnet_ids,\n",
                "                            ),\n",
                "                            tags=tags)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "13bdf8ca-1f2c-4da8-ab41-695d00e445f4",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "# setup input from S3, note the ShardedByS3Key, this ensures that \n",
                "# each instance gets a random and equal subset of the files in S3.\n",
                "inputs = [ProcessingInput(source=\"./data\",\n",
                "                          destination='/opt/ml/processing/input',\n",
                "                          s3_data_distribution_type='ShardedByS3Key',\n",
                "                          s3_data_type='S3Prefix')]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "24fdf937-eaf6-439e-a602-e0d0504d3d58",
            "metadata": {
                "collapsed": true,
                "jupyter": {
                    "outputs_hidden": true
                },
                "tags": []
            },
            "outputs": [],
            "source": [
                "logger.info(f\"creating an opensearch index with name=document\")\n",
                "\n",
                "# ready to run the processing job\n",
                "st = time.time()\n",
                "processor.run(code=\"container/load_data_into_opensearch.py\",\n",
                "              inputs=inputs,\n",
                "              outputs=[],\n",
                "              arguments=[\"--opensearch-endpoint\", opensearch_domain_endpoint,\n",
                "                         \"--opensearch-secret-id\", opensearch_secret_id,\n",
                "                         \"--aws-region\", aws_region,\n",
                "                         \"--input-data-dir\", \"/opt/ml/processing/input\"\n",
                "])\n",
                "\n",
                "time_taken = time.time() - st\n",
                "logger.info(f\"processing job completed, total time taken={time_taken}s\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "4ba183b4-79a9-4d71-bc73-7194d8dfe6fc",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "preprocessing_job_description = processor.jobs[-1].describe()\n",
                "logger.info(preprocessing_job_description)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6e29eae5-c463-4153-9167-e4628c74d13c",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Cleanup\n",
                "\n",
                "To avoid incurring future charges, delete the resources. You can do this by deleting the CloudFormation template used to create the IAM role and SageMaker notebook."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "59ce3fe8-bb71-4e22-a551-2475eb2d16b7",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Conclusion\n",
                "In this notebook we were able to see how to use LLMs deployed on a SageMaker Endpoint to generate embeddings and then ingest those embeddings into OpenSearch and finally do a similarity search for user input to the documents (embeddings) stored in OpenSearch. We used langchain as an abstraction layer to talk to both the SageMaker Endpoint as well as OpenSearch."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dd881bab",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## References\n",
                "\n",
                "  * [Build production-ready generative AI applications for enterprise search using Haystack pipelines and Amazon SageMaker JumpStart with LLMs 2023-0-14)](https://aws.amazon.com/blogs/machine-learning/build-production-ready-generative-ai-applications-for-enterprise-search-using-haystack-pipelines-and-amazon-sagemaker-jumpstart-with-llms/)\n",
                "    * [Haystack Retrieval-Augmented Generative QA Pipelines with SageMaker JumpStart](https://github.com/deepset-ai/haystack-sagemaker/)\n",
                "  * [Using the Amazon SageMaker Studio Image Build CLI to build container images from your Studio notebooks](https://aws.amazon.com/blogs/machine-learning/using-the-amazon-sagemaker-studio-image-build-cli-to-build-container-images-from-your-studio-notebooks/)\n",
                "  * [Haystack](https://docs.haystack.deepset.ai/docs) - The open source Python framework by deepset for building custom apps with large language models (LLMs)."
            ]
        }
    ],
    "metadata": {
        "availableInstances": [
            {
                "_defaultOrder": 0,
                "_isFastLaunch": true,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 4,
                "name": "ml.t3.medium",
                "vcpuNum": 2
            },
            {
                "_defaultOrder": 1,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 8,
                "name": "ml.t3.large",
                "vcpuNum": 2
            },
            {
                "_defaultOrder": 2,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.t3.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 3,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.t3.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 4,
                "_isFastLaunch": true,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 8,
                "name": "ml.m5.large",
                "vcpuNum": 2
            },
            {
                "_defaultOrder": 5,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.m5.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 6,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.m5.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 7,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 64,
                "name": "ml.m5.4xlarge",
                "vcpuNum": 16
            },
            {
                "_defaultOrder": 8,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 128,
                "name": "ml.m5.8xlarge",
                "vcpuNum": 32
            },
            {
                "_defaultOrder": 9,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 192,
                "name": "ml.m5.12xlarge",
                "vcpuNum": 48
            },
            {
                "_defaultOrder": 10,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 256,
                "name": "ml.m5.16xlarge",
                "vcpuNum": 64
            },
            {
                "_defaultOrder": 11,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 384,
                "name": "ml.m5.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 12,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 8,
                "name": "ml.m5d.large",
                "vcpuNum": 2
            },
            {
                "_defaultOrder": 13,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.m5d.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 14,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.m5d.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 15,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 64,
                "name": "ml.m5d.4xlarge",
                "vcpuNum": 16
            },
            {
                "_defaultOrder": 16,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 128,
                "name": "ml.m5d.8xlarge",
                "vcpuNum": 32
            },
            {
                "_defaultOrder": 17,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 192,
                "name": "ml.m5d.12xlarge",
                "vcpuNum": 48
            },
            {
                "_defaultOrder": 18,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 256,
                "name": "ml.m5d.16xlarge",
                "vcpuNum": 64
            },
            {
                "_defaultOrder": 19,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 384,
                "name": "ml.m5d.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 20,
                "_isFastLaunch": false,
                "category": "General purpose",
                "gpuNum": 0,
                "hideHardwareSpecs": true,
                "memoryGiB": 0,
                "name": "ml.geospatial.interactive",
                "supportedImageNames": [
                    "sagemaker-geospatial-v1-0"
                ],
                "vcpuNum": 0
            },
            {
                "_defaultOrder": 21,
                "_isFastLaunch": true,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 4,
                "name": "ml.c5.large",
                "vcpuNum": 2
            },
            {
                "_defaultOrder": 22,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 8,
                "name": "ml.c5.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 23,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.c5.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 24,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.c5.4xlarge",
                "vcpuNum": 16
            },
            {
                "_defaultOrder": 25,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 72,
                "name": "ml.c5.9xlarge",
                "vcpuNum": 36
            },
            {
                "_defaultOrder": 26,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 96,
                "name": "ml.c5.12xlarge",
                "vcpuNum": 48
            },
            {
                "_defaultOrder": 27,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 144,
                "name": "ml.c5.18xlarge",
                "vcpuNum": 72
            },
            {
                "_defaultOrder": 28,
                "_isFastLaunch": false,
                "category": "Compute optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 192,
                "name": "ml.c5.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 29,
                "_isFastLaunch": true,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.g4dn.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 30,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.g4dn.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 31,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 64,
                "name": "ml.g4dn.4xlarge",
                "vcpuNum": 16
            },
            {
                "_defaultOrder": 32,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 128,
                "name": "ml.g4dn.8xlarge",
                "vcpuNum": 32
            },
            {
                "_defaultOrder": 33,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 4,
                "hideHardwareSpecs": false,
                "memoryGiB": 192,
                "name": "ml.g4dn.12xlarge",
                "vcpuNum": 48
            },
            {
                "_defaultOrder": 34,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 256,
                "name": "ml.g4dn.16xlarge",
                "vcpuNum": 64
            },
            {
                "_defaultOrder": 35,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 61,
                "name": "ml.p3.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 36,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 4,
                "hideHardwareSpecs": false,
                "memoryGiB": 244,
                "name": "ml.p3.8xlarge",
                "vcpuNum": 32
            },
            {
                "_defaultOrder": 37,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 8,
                "hideHardwareSpecs": false,
                "memoryGiB": 488,
                "name": "ml.p3.16xlarge",
                "vcpuNum": 64
            },
            {
                "_defaultOrder": 38,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 8,
                "hideHardwareSpecs": false,
                "memoryGiB": 768,
                "name": "ml.p3dn.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 39,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.r5.large",
                "vcpuNum": 2
            },
            {
                "_defaultOrder": 40,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.r5.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 41,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 64,
                "name": "ml.r5.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 42,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 128,
                "name": "ml.r5.4xlarge",
                "vcpuNum": 16
            },
            {
                "_defaultOrder": 43,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 256,
                "name": "ml.r5.8xlarge",
                "vcpuNum": 32
            },
            {
                "_defaultOrder": 44,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 384,
                "name": "ml.r5.12xlarge",
                "vcpuNum": 48
            },
            {
                "_defaultOrder": 45,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 512,
                "name": "ml.r5.16xlarge",
                "vcpuNum": 64
            },
            {
                "_defaultOrder": 46,
                "_isFastLaunch": false,
                "category": "Memory Optimized",
                "gpuNum": 0,
                "hideHardwareSpecs": false,
                "memoryGiB": 768,
                "name": "ml.r5.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 47,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 16,
                "name": "ml.g5.xlarge",
                "vcpuNum": 4
            },
            {
                "_defaultOrder": 48,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 32,
                "name": "ml.g5.2xlarge",
                "vcpuNum": 8
            },
            {
                "_defaultOrder": 49,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 64,
                "name": "ml.g5.4xlarge",
                "vcpuNum": 16
            },
            {
                "_defaultOrder": 50,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 128,
                "name": "ml.g5.8xlarge",
                "vcpuNum": 32
            },
            {
                "_defaultOrder": 51,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 1,
                "hideHardwareSpecs": false,
                "memoryGiB": 256,
                "name": "ml.g5.16xlarge",
                "vcpuNum": 64
            },
            {
                "_defaultOrder": 52,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 4,
                "hideHardwareSpecs": false,
                "memoryGiB": 192,
                "name": "ml.g5.12xlarge",
                "vcpuNum": 48
            },
            {
                "_defaultOrder": 53,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 4,
                "hideHardwareSpecs": false,
                "memoryGiB": 384,
                "name": "ml.g5.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 54,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 8,
                "hideHardwareSpecs": false,
                "memoryGiB": 768,
                "name": "ml.g5.48xlarge",
                "vcpuNum": 192
            },
            {
                "_defaultOrder": 55,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 8,
                "hideHardwareSpecs": false,
                "memoryGiB": 1152,
                "name": "ml.p4d.24xlarge",
                "vcpuNum": 96
            },
            {
                "_defaultOrder": 56,
                "_isFastLaunch": false,
                "category": "Accelerated computing",
                "gpuNum": 8,
                "hideHardwareSpecs": false,
                "memoryGiB": 1152,
                "name": "ml.p4de.24xlarge",
                "vcpuNum": 96
            }
        ],
        "instance_type": "ml.t3.medium",
        "kernelspec": {
            "display_name": "Python 3 (Data Science 3.0)",
            "language": "python",
            "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}